{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üå± Carbon Tracking Demo\n",
    "\n",
    "> **Comprehensive sustainability monitoring for ML workloads with actionable insights**\n",
    "\n",
    "This notebook demonstrates cutting-edge carbon footprint tracking capabilities including:\n",
    "\n",
    "- üåç **Real carbon tracking** with CodeCarbon integration and regional optimization\n",
    "- ‚òÅÔ∏è **Automatic cloud provider detection** (GCP, AWS, Azure) with regional recommendations\n",
    "- üìä **Intuitive impact comparisons** (phone charges, car driving, tree absorption)\n",
    "- üí° **Sustainability recommendations** for cost and carbon optimization\n",
    "- üìà **Historical tracking** and carbon budgeting for teams and projects\n",
    "- üéØ **Business reporting** for corporate sustainability goals and ESG compliance\n",
    "\n",
    "**Use Case:** Enable sustainable ML development by providing real-time carbon tracking, actionable optimization recommendations, and comprehensive sustainability reporting for corporate ESG initiatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ML Cookbook carbon tracking suite\n",
    "from cookbook.measure import (\n",
    "    CarbonTracker,\n",
    "    CarbonMetrics,\n",
    "    CarbonAwareProfiler\n",
    ")\n",
    "\n",
    "# Standard ML libraries for demonstration\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure plotting with sustainability theme\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "# Green-focused color palette for sustainability theme\n",
    "sustainability_colors = ['#2ecc71', '#27ae60', '#16a085', '#f39c12', '#e74c3c']\n",
    "sns.set_palette(sustainability_colors)\n",
    "\n",
    "print(\"üå± ML COOKBOOK - CARBON TRACKING DEMO\")\n",
    "print(\"=\" * 55)\n",
    "print(\"Demonstrating comprehensive sustainability monitoring for ML workloads\")\n",
    "print(\"Focus: Real carbon tracking with actionable optimization insights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåç Demo 1: Basic Carbon Tracking Setup\n",
    "\n",
    "Let's start with basic carbon tracking configuration and cloud provider detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize carbon tracker with automatic cloud detection\n",
    "tracker = CarbonTracker(\n",
    "    project_name=\"sustainable-ml-demo\",\n",
    "    experiment_name=\"carbon-tracking-showcase\",\n",
    "    output_dir=\"./carbon_logs\",\n",
    "    # Cloud provider and region will be auto-detected\n",
    "    country_iso_code=\"US\",  # Specify if known\n",
    "    tracking_mode=\"machine\"\n",
    ")\n",
    "\n",
    "print(\"üå± CARBON TRACKER INITIALIZATION\")\n",
    "print(\"=\" * 42)\n",
    "print(f\"Project: {tracker.project_name}\")\n",
    "print(f\"Experiment: {tracker.experiment_name}\")\n",
    "print(f\"Output Directory: {tracker.output_dir}\")\n",
    "print(f\"Cloud Provider: {tracker.cloud_provider}\")\n",
    "print(f\"Cloud Region: {tracker.cloud_region}\")\n",
    "print(f\"Tracking Mode: {tracker.tracking_mode}\")\n",
    "\n",
    "# Display initial carbon intensity info if available\n",
    "if tracker.cloud_provider != \"unknown\":\n",
    "    print(f\"\\n‚òÅÔ∏è Cloud Environment Detected:\")\n",
    "    print(f\"   Provider: {tracker.cloud_provider.upper()}\")\n",
    "    print(f\"   Region: {tracker.cloud_region}\")\n",
    "    print(f\"   Optimization: Regional carbon intensity will be used\")\nelse:\n",
    "    print(f\"\\nüíª Local Environment:\")\n",
    "    print(f\"   Running on local machine\")\n",
    "    print(f\"   Carbon intensity based on grid data\")\n",
    "\n",
    "print(f\"\\n‚úÖ Carbon tracker ready for sustainability monitoring!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Demo 2: ML Workload Carbon Tracking\n",
    "\n",
    "Track carbon emissions from different types of ML workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different ML workload types to track\n",
    "workload_scenarios = {\n",
    "    \"data_preprocessing\": {\n",
    "        \"description\": \"CPU-intensive data cleaning and feature engineering\",\n",
    "        \"simulation_time\": 0.3,\n",
    "        \"compute_intensity\": \"light\"\n",
    "    },\n",
    "    \"model_training\": {\n",
    "        \"description\": \"GPU-intensive neural network training\",\n",
    "        \"simulation_time\": 0.8,\n",
    "        \"compute_intensity\": \"heavy\"\n",
    "    },\n",
    "    \"hyperparameter_search\": {\n",
    "        \"description\": \"Multiple training runs for optimization\",\n",
    "        \"simulation_time\": 0.5,\n",
    "        \"compute_intensity\": \"medium\"\n",
    "    },\n",
    "    \"model_inference\": {\n",
    "        \"description\": \"Batch inference on production data\",\n",
    "        \"simulation_time\": 0.2,\n",
    "        \"compute_intensity\": \"light\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üß™ TRACKING CARBON EMISSIONS ACROSS ML WORKLOADS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "workload_results = []\n",
    "\n",
    "for workload_name, workload_info in workload_scenarios.items():\n",
    "    print(f\"\\nüî¨ Tracking: {workload_name.replace('_', ' ').title()}\")\n",
    "    print(f\"   Description: {workload_info['description']}\")\n",
    "    \n",
    "    # Start carbon tracking for this workload\n",
    "    with tracker.start_tracking(workload_name) as session:\n",
    "        \n",
    "        # Simulate different types of ML computation\n",
    "        if workload_info['compute_intensity'] == 'heavy':\n",
    "            # Simulate GPU-intensive training\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            \n",
    "            # Create a moderately complex model\n",
    "            model = nn.Sequential(\n",
    "                nn.Linear(1024, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 10)\n",
    "            ).to(device)\n",
    "            \n",
    "            optimizer = torch.optim.Adam(model.parameters())\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            \n",
    "            # Simulate training steps\n",
    "            for step in range(20):\n",
    "                x = torch.randn(64, 1024).to(device)\n",
    "                y = torch.randint(0, 10, (64,)).to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                if step % 5 == 0:\n",
    "                    print(f\"      Step {step:2d}/20 - Loss: {loss.item():.4f}\")\n",
    "                    \n",
    "        elif workload_info['compute_intensity'] == 'medium':\n",
    "            # Simulate multiple smaller training runs (hyperparameter search)\n",
    "            for run in range(5):\n",
    "                # Smaller models for hyperparameter search\n",
    "                x = np.random.randn(1000, 100)\n",
    "                y = np.random.randn(1000, 1)\n",
    "                \n",
    "                # Simulate simple ML operations\n",
    "                for _ in range(10):\n",
    "                    weights = np.random.randn(100, 1)\n",
    "                    pred = np.dot(x, weights)\n",
    "                    loss = np.mean((pred - y) ** 2)\n",
    "                \n",
    "                print(f\"      HP Search Run {run+1}/5 completed\")\n",
    "                time.sleep(0.05)  # Brief pause between runs\n",
    "        \n",
    "        else:  # light compute\n",
    "            # Simulate data processing or inference\n",
    "            for batch in range(10):\n",
    "                # Light CPU operations\n",
    "                data = np.random.randn(100, 50)\n",
    "                processed = np.mean(data, axis=1)\n",
    "                normalized = (processed - np.mean(processed)) / np.std(processed)\n",
    "                \n",
    "                if batch % 3 == 0:\n",
    "                    print(f\"      Batch {batch+1}/10 processed\")\n",
    "                time.sleep(0.02)  # Light processing delay\n",
    "        \n",
    "        # Add realistic wait time based on workload\n",
    "        time.sleep(workload_info['simulation_time'])\n",
    "    \n",
    "    # Get carbon metrics for this workload\n",
    "    metrics = tracker.stop_tracking(workload_name)\n",
    "    \n",
    "    workload_results.append({\n",
    "        \"workload\": workload_name.replace('_', ' ').title(),\n",
    "        \"description\": workload_info['description'],\n",
    "        \"duration_seconds\": metrics.duration_seconds,\n",
    "        \"emissions_g_co2\": metrics.emissions_kg_co2 * 1000,\n",
    "        \"energy_wh\": metrics.energy_consumed_kwh * 1000,\n",
    "        \"compute_intensity\": workload_info['compute_intensity']\n",
    "    })\n",
    "    \n",
    "    print(f\"   ‚úÖ Completed - Emissions: {metrics.emissions_kg_co2 * 1000:.3f}g CO2eq\")\n",
    "    print(f\"      Duration: {metrics.duration_seconds:.1f}s, Energy: {metrics.energy_consumed_kwh * 1000:.2f}Wh\")\n",
    "\n",
    "print(f\"\\nüå± All ML workloads tracked successfully!\")\n",
    "print(f\"üìä Ready for comprehensive carbon analysis...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Demo 3: Carbon Impact Analysis & Visualization\n",
    "\n",
    "Generate professional visualizations and intuitive impact comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive carbon analysis\n",
    "results_df = pd.DataFrame(workload_results)\n",
    "total_emissions = results_df['emissions_g_co2'].sum()\n",
    "total_energy = results_df['energy_wh'].sum()\n",
    "total_duration = results_df['duration_seconds'].sum()\n",
    "\n",
    "print(\"üìä COMPREHENSIVE CARBON IMPACT ANALYSIS\")\n",
    "print(\"=\" * 48)\n",
    "print(f\"Total Pipeline Emissions: {total_emissions:.2f}g CO2eq\")\n",
    "print(f\"Total Energy Consumed: {total_energy:.2f} Wh\")\n",
    "print(f\"Total Execution Time: {total_duration:.1f} seconds\")\n",
    "print(f\"Average Emission Rate: {total_emissions / (total_duration / 3600):.2f}g CO2/hour\")\n",
    "\n",
    "# Display workload breakdown\n",
    "print(f\"\\nüìã WORKLOAD BREAKDOWN:\")\n",
    "workload_summary = results_df[['workload', 'emissions_g_co2', 'energy_wh', 'duration_seconds']].copy()\n",
    "workload_summary['emissions_percent'] = (workload_summary['emissions_g_co2'] / total_emissions * 100).round(1)\n",
    "print(workload_summary.round(3))\n",
    "\n",
    "# Generate intuitive impact comparisons\n",
    "print(f\"\\nüåç INTUITIVE IMPACT COMPARISONS:\")\n",
    "comparisons = {\n",
    "    \"smartphone_charges\": total_emissions / 8.5,  # ~8.5g CO2 per charge\n",
    "    \"car_driving_meters\": total_emissions / 0.2,   # ~0.2g CO2 per meter\n",
    "    \"led_bulb_hours\": total_energy / 10,           # ~10W LED bulb\n",
    "    \"tree_absorption_minutes\": (total_emissions / 1000) / 21.7 * 365 * 24 * 60  # Tree absorbs ~21.7kg CO2/year\n",
    "}\n",
    "\n",
    "for comparison, value in comparisons.items():\n",
    "    readable_name = comparison.replace('_', ' ').title()\n",
    "    if 'minutes' in comparison:\n",
    "        if value < 60:\n",
    "            print(f\"   üìå {readable_name}: {value:.1f} minutes\")\n",
    "        elif value < 1440:  # less than a day\n",
    "            print(f\"   üìå Tree Absorption Hours: {value/60:.1f} hours\")\n",
    "        else:\n",
    "            print(f\"   üìå Tree Absorption Days: {value/1440:.1f} days\")\n",
    "    elif 'meters' in comparison:\n",
    "        if value > 1000:\n",
    "            print(f\"   üöó Car Driving: {value/1000:.2f} kilometers\")\n",
    "        else:\n",
    "            print(f\"   üöó {readable_name}: {value:.0f} meters\")\n",
    "    else:\n",
    "        print(f\"   üì± {readable_name}: {value:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create professional carbon impact dashboard\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('üå± ML Pipeline Carbon Impact Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Emissions by workload (pie chart)\n",
    "colors = plt.cm.Greens(np.linspace(0.4, 0.9, len(results_df)))\n",
    "wedges, texts, autotexts = ax1.pie(results_df['emissions_g_co2'], \n",
    "                                  labels=results_df['workload'],\n",
    "                                  autopct='%1.1f%%',\n",
    "                                  colors=colors,\n",
    "                                  startangle=90)\n",
    "ax1.set_title('üî• Carbon Emissions by Workload', fontweight='bold')\n",
    "\n",
    "# Enhance pie chart text\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "\n",
    "# Plot 2: Energy consumption comparison\n",
    "bars = ax2.bar(results_df['workload'], results_df['energy_wh'], \n",
    "              color=sustainability_colors[:len(results_df)], alpha=0.8)\n",
    "ax2.set_title('‚ö° Energy Consumption by Workload', fontweight='bold')\n",
    "ax2.set_ylabel('Energy (Wh)')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, energy in zip(bars, results_df['energy_wh']):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + max(results_df['energy_wh'])*0.01,\n",
    "             f'{energy:.1f}Wh', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "# Plot 3: Emissions intensity (g CO2 per second)\n",
    "results_df['emissions_intensity'] = results_df['emissions_g_co2'] / results_df['duration_seconds']\n",
    "ax3.scatter(results_df['duration_seconds'], results_df['emissions_g_co2'], \n",
    "           s=results_df['energy_wh'] * 5,  # Size by energy consumption\n",
    "           c=results_df['emissions_intensity'],\n",
    "           cmap='RdYlGn_r', alpha=0.7)\n",
    "\n",
    "# Add workload labels\n",
    "for i, txt in enumerate(results_df['workload']):\n",
    "    ax3.annotate(txt, (results_df['duration_seconds'].iloc[i], results_df['emissions_g_co2'].iloc[i]),\n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=8, alpha=0.8)\n",
    "\n",
    "ax3.set_title('‚è±Ô∏è Duration vs Emissions\\n(bubble size = energy)', fontweight='bold')\n",
    "ax3.set_xlabel('Duration (seconds)')\n",
    "ax3.set_ylabel('Emissions (g CO2eq)')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Comparison with everyday activities\n",
    "comparison_names = ['Smartphone\\nCharges', 'LED Bulb\\nHours', 'Car Driving\\n(meters)']\n",
    "comparison_values = [comparisons['smartphone_charges'], \n",
    "                    comparisons['led_bulb_hours'],\n",
    "                    comparisons['car_driving_meters']]\n",
    "\n",
    "bars_comp = ax4.bar(comparison_names, comparison_values, \n",
    "                   color=['#3498db', '#f1c40f', '#e74c3c'], alpha=0.7)\n",
    "ax4.set_title('üåç Equivalent Environmental Impact', fontweight='bold')\n",
    "ax4.set_ylabel('Equivalent Units')\n",
    "\n",
    "# Add value labels\n",
    "for bar, value in zip(bars_comp, comparison_values):\n",
    "    height = bar.get_height()\n",
    "    if value > 100:\n",
    "        label = f'{value:.0f}'\n",
    "    elif value > 10:\n",
    "        label = f'{value:.1f}'\n",
    "    else:\n",
    "        label = f'{value:.2f}'\n",
    "    \n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height + max(comparison_values)*0.01,\n",
    "             label, ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save dashboard for reporting\n",
    "dashboard_path = Path('./carbon_logs/carbon_dashboard.png')\n",
    "dashboard_path.parent.mkdir(exist_ok=True)\n",
    "plt.savefig(dashboard_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nüíæ Carbon dashboard saved to: {dashboard_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Demo 4: Sustainability Recommendations\n",
    "\n",
    "Generate actionable recommendations for reducing carbon footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive sustainability analysis and recommendations\n",
    "print(\"üí° SUSTAINABILITY OPTIMIZATION RECOMMENDATIONS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Analyze workload efficiency\n",
    "most_efficient_workload = results_df.loc[results_df['emissions_intensity'].idxmin()]\n",
    "least_efficient_workload = results_df.loc[results_df['emissions_intensity'].idxmax()]\n",
    "highest_impact_workload = results_df.loc[results_df['emissions_g_co2'].idxmax()]\n",
    "\n",
    "print(f\"üìä EFFICIENCY ANALYSIS:\")\n",
    "print(f\"   Most Efficient: {most_efficient_workload['workload']} ({most_efficient_workload['emissions_intensity']:.4f}g CO2/s)\")\n",
    "print(f\"   Least Efficient: {least_efficient_workload['workload']} ({least_efficient_workload['emissions_intensity']:.4f}g CO2/s)\")\n",
    "print(f\"   Highest Total Impact: {highest_impact_workload['workload']} ({highest_impact_workload['emissions_g_co2']:.2f}g CO2)\")\n",
    "\n",
    "# Generate specific recommendations\n",
    "recommendations = []\n",
    "\n",
    "# Workload-specific recommendations\n",
    "training_workloads = results_df[results_df['workload'].str.contains('Training|Search', case=False)]\n",
    "if not training_workloads.empty:\n",
    "    avg_training_emissions = training_workloads['emissions_g_co2'].mean()\n",
    "    if avg_training_emissions > total_emissions * 0.4:  # If training is >40% of total\n",
    "        recommendations.append({\n",
    "            \"category\": \"üèãÔ∏è Training Optimization\",\n",
    "            \"priority\": \"High\",\n",
    "            \"recommendation\": \"Training workloads dominate emissions. Consider mixed precision, gradient accumulation, or early stopping.\",\n",
    "            \"potential_savings\": \"20-40% emission reduction\",\n",
    "            \"implementation\": \"Use FP16 training, implement learning rate scheduling, add validation-based early stopping\"\n",
    "        })\n",
    "\n",
    "# Cloud region recommendations\n",
    "if tracker.cloud_provider != \"unknown\":\n",
    "    low_carbon_regions = {\n",
    "        \"gcp\": [\"europe-north1\", \"us-west1\", \"europe-west4\"],\n",
    "        \"aws\": [\"eu-north-1\", \"us-west-2\", \"ca-central-1\"],\n",
    "        \"azure\": [\"north-europe\", \"west-us-2\", \"canada-central\"]\n",
    "    }\n",
    "    \n",
    "    if tracker.cloud_provider in low_carbon_regions:\n",
    "        recommended_regions = low_carbon_regions[tracker.cloud_provider]\n",
    "        recommendations.append({\n",
    "            \"category\": \"‚òÅÔ∏è Regional Optimization\",\n",
    "            \"priority\": \"Medium\",\n",
    "            \"recommendation\": f\"Consider moving workloads to lower-carbon regions: {', '.join(recommended_regions[:2])}.\",\n",
    "            \"potential_savings\": \"10-60% emission reduction\",\n",
    "            \"implementation\": \"Migrate training jobs to regions with cleaner energy grids\"\n",
    "        })\n",
    "\n",
    "# Scheduling recommendations\n",
    "recommendations.append({\n",
    "    \"category\": \"‚è∞ Temporal Optimization\",\n",
    "    \"priority\": \"Medium\",\n",
    "    \"recommendation\": \"Schedule carbon-intensive workloads during low-demand hours when grid carbon intensity is lower.\",\n",
    "    \"potential_savings\": \"5-25% emission reduction\",\n",
    "    \"implementation\": \"Use job schedulers to run training during off-peak hours (2-6 AM local time)\"\n",
    "})\n",
    "\n",
    "# Model efficiency recommendations\n",
    "if highest_impact_workload['emissions_g_co2'] > total_emissions * 0.5:\n",
    "    recommendations.append({\n",
    "        \"category\": \"ü§ñ Model Architecture\",\n",
    "        \"priority\": \"High\",\n",
    "        \"recommendation\": \"High-impact workload detected. Consider model compression, pruning, or efficient architectures.\",\n",
    "        \"potential_savings\": \"30-70% emission reduction\",\n",
    "        \"implementation\": \"Implement knowledge distillation, network pruning, or use EfficientNet-style architectures\"\n",
    "    })\n",
    "\n",
    "# Infrastructure recommendations\n",
    "recommendations.append({\n",
    "    \"category\": \"üíª Infrastructure\",\n",
    "    \"priority\": \"Low\",\n",
    "    \"recommendation\": \"Consider spot/preemptible instances for non-critical workloads to reduce waste from interrupted jobs.\",\n",
    "    \"potential_savings\": \"10-30% cost and carbon reduction\",\n",
    "    \"implementation\": \"Use fault-tolerant training with checkpoint resumption on spot instances\"\n",
    "})\n",
    "\n",
    "# Display recommendations\n",
    "print(f\"\\nüí° ACTIONABLE RECOMMENDATIONS:\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"\\n{i}. {rec['category']} (Priority: {rec['priority']})\")\n",
    "    print(f\"   üìã Recommendation: {rec['recommendation']}\")\n",
    "    print(f\"   üíö Potential Savings: {rec['potential_savings']}\")\n",
    "    print(f\"   üîß Implementation: {rec['implementation']}\")\n",
    "\n",
    "# Carbon budget analysis\n",
    "print(f\"\\nüìä CARBON BUDGET ANALYSIS:\")\n",
    "\n",
    "# Simulate different budget scenarios\n",
    "daily_budget_scenarios = {\n",
    "    \"Conservative\": 50,    # 50g CO2 per day\n",
    "    \"Moderate\": 200,      # 200g CO2 per day  \n",
    "    \"Aggressive\": 500     # 500g CO2 per day\n",
    "}\n",
    "\n",
    "print(f\"   Current pipeline emissions: {total_emissions:.2f}g CO2\")\n",
    "print(f\"   \\nüìÖ Daily Budget Scenarios:\")\n",
    "\n",
    "for scenario, budget in daily_budget_scenarios.items():\n",
    "    runs_per_day = budget / total_emissions\n",
    "    days_per_month = 30\n",
    "    monthly_emissions = budget * days_per_month\n",
    "    \n",
    "    print(f\"     {scenario}: {budget}g CO2/day\")\n",
    "    print(f\"       ‚Üí {runs_per_day:.1f} pipeline runs per day\")\n",
    "    print(f\"       ‚Üí {monthly_emissions/1000:.1f}kg CO2/month\")\n",
    "    \n",
    "    if runs_per_day >= 5:\n",
    "        feasibility = \"‚úÖ Feasible for active development\"\n",
    "    elif runs_per_day >= 1:\n",
    "        feasibility = \"‚ö†Ô∏è Limited - suitable for production only\"\n",
    "    else:\n",
    "        feasibility = \"‚ùå Too restrictive - optimization required\"\n",
    "    \n",
    "    print(f\"       ‚Üí {feasibility}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè¢ Demo 5: Corporate Reporting & ESG Compliance\n",
    "\n",
    "Generate comprehensive sustainability reports for corporate ESG initiatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive corporate sustainability report\n",
    "print(\"üè¢ CORPORATE SUSTAINABILITY REPORT\")\n",
    "print(\"=\" * 42)\n",
    "\n",
    "# Simulate quarterly and annual projections\n",
    "quarterly_scaling_factor = 90  # 90 days\n",
    "annual_scaling_factor = 365    # 365 days\n",
    "\n",
    "# Assume current pipeline runs 2x per day on average\n",
    "daily_runs = 2\n",
    "quarterly_emissions = total_emissions * daily_runs * quarterly_scaling_factor / 1000  # Convert to kg\n",
    "annual_emissions = total_emissions * daily_runs * annual_scaling_factor / 1000\n",
    "\n",
    "# Corporate ESG metrics\n",
    "corporate_metrics = {\n",
    "    \"reporting_period\": \"Q4 2025 (Projected)\",\n",
    "    \"ml_team_size\": 12,\n",
    "    \"daily_pipeline_runs\": daily_runs,\n",
    "    \"quarterly_emissions_kg\": quarterly_emissions,\n",
    "    \"annual_projection_kg\": annual_emissions,\n",
    "    \"annual_projection_tonnes\": annual_emissions / 1000,\n",
    "    \"carbon_intensity_per_developer\": annual_emissions / 12,  # kg CO2 per developer\n",
    "    \"equivalent_car_km_annually\": annual_emissions / 0.0002,  # km of car driving\n",
    "    \"equivalent_tree_years\": annual_emissions / 21.7,  # trees needed for 1 year\n",
    "}\n",
    "\n",
    "print(f\"üìä EXECUTIVE SUMMARY:\")\n",
    "print(f\"   Reporting Period: {corporate_metrics['reporting_period']}\")\n",
    "print(f\"   ML Team Size: {corporate_metrics['ml_team_size']} developers\")\n",
    "print(f\"   Daily ML Pipeline Runs: {corporate_metrics['daily_pipeline_runs']}\")\n",
    "print(f\"\\nüåç CARBON FOOTPRINT:\")\n",
    "print(f\"   Quarterly Emissions: {corporate_metrics['quarterly_emissions_kg']:.2f} kg CO2eq\")\n",
    "print(f\"   Annual Projection: {corporate_metrics['annual_projection_tonnes']:.3f} tonnes CO2eq\")\n",
    "print(f\"   Per Developer Impact: {corporate_metrics['carbon_intensity_per_developer']:.1f} kg CO2eq/year\")\n",
    "\n",
    "print(f\"\\nüéØ CONTEXTUAL BENCHMARKS:\")\n",
    "print(f\"   Equivalent to {corporate_metrics['equivalent_car_km_annually']:.0f} km of car driving annually\")\n",
    "print(f\"   Requires {corporate_metrics['equivalent_tree_years']:.1f} trees growing for 1 year to offset\")\n",
    "\n",
    "# Industry benchmarking (simulated)\n",
    "industry_benchmarks = {\n",
    "    \"software_industry_avg_kg_per_dev\": 850,      # Industry average\n",
    "    \"ai_company_avg_kg_per_dev\": 1200,            # AI companies average\n",
    "    \"sustainable_leader_kg_per_dev\": 400,         # Sustainability leaders\n",
    "}\n",
    "\n",
    "our_intensity = corporate_metrics['carbon_intensity_per_developer']\n",
    "\n",
    "print(f\"\\nüìà INDUSTRY BENCHMARKING:\")\n",
    "for benchmark_name, benchmark_value in industry_benchmarks.items():\n",
    "    comparison = \"above\" if our_intensity > benchmark_value else \"below\"\n",
    "    percentage_diff = abs((our_intensity - benchmark_value) / benchmark_value) * 100\n",
    "    status = \"üî¥\" if comparison == \"above\" else \"üü¢\"\n",
    "    \n",
    "    readable_name = benchmark_name.replace('_', ' ').replace('kg per dev', '').title()\n",
    "    print(f\"   {status} {readable_name}: {percentage_diff:.1f}% {comparison} benchmark ({benchmark_value} kg/dev)\")\n",
    "\n",
    "# Sustainability goals and targets\n",
    "print(f\"\\nüéØ SUSTAINABILITY TARGETS:\")\n",
    "\n",
    "# Common corporate targets\n",
    "targets = {\n",
    "    \"2025_reduction_target\": 0.15,   # 15% reduction\n",
    "    \"2030_reduction_target\": 0.50,   # 50% reduction  \n",
    "    \"2040_net_zero_target\": 0.95,    # 95% reduction (net zero)\n",
    "}\n",
    "\n",
    "baseline_emissions = annual_emissions\n",
    "\n",
    "for target_name, reduction_pct in targets.items():\n",
    "    target_year = target_name.split('_')[0]\n",
    "    target_emissions = baseline_emissions * (1 - reduction_pct)\n",
    "    reduction_needed = baseline_emissions - target_emissions\n",
    "    \n",
    "    if \"net_zero\" in target_name:\n",
    "        target_desc = f\"{target_year} Net Zero\"\n",
    "        target_detail = f\"‚â§{target_emissions:.1f} kg CO2eq (95% reduction + offsetting)\"\n",
    "    else:\n",
    "        target_desc = f\"{target_year} Reduction Target\"\n",
    "        target_detail = f\"‚â§{target_emissions:.1f} kg CO2eq ({reduction_pct*100:.0f}% reduction)\"\n",
    "    \n",
    "    print(f\"   üìÖ {target_desc}: {target_detail}\")\n",
    "    print(f\"      Required reduction: {reduction_needed:.1f} kg CO2eq annually\")\n",
    "\n",
    "# Calculate offset costs\n",
    "carbon_offset_cost_per_tonne = 25  # $25 per tonne CO2 (typical voluntary carbon offset)\n",
    "annual_offset_cost = corporate_metrics['annual_projection_tonnes'] * carbon_offset_cost_per_tonne\n",
    "\n",
    "print(f\"\\nüí∞ CARBON OFFSET ECONOMICS:\")\n",
    "print(f\"   Current Annual Offset Cost: ${annual_offset_cost:.2f} (at ${carbon_offset_cost_per_tonne}/tonne)\")\n",
    "print(f\"   Per Developer Offset Cost: ${annual_offset_cost / corporate_metrics['ml_team_size']:.2f}/year\")\n",
    "print(f\"   Per Pipeline Run Cost: ${(annual_offset_cost / (daily_runs * 365)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive sustainability report\n",
    "sustainability_report = {\n",
    "    \"report_metadata\": {\n",
    "        \"report_title\": \"ML Engineering Team - Carbon Footprint Analysis\",\n",
    "        \"reporting_period\": corporate_metrics['reporting_period'],\n",
    "        \"generated_date\": datetime.now().isoformat(),\n",
    "        \"report_version\": \"1.0\",\n",
    "        \"scope\": \"ML development pipeline carbon emissions\"\n",
    "    },\n",
    "    \"executive_summary\": {\n",
    "        \"team_size\": corporate_metrics['ml_team_size'],\n",
    "        \"annual_emissions_kg\": float(corporate_metrics['annual_projection_kg']),\n",
    "        \"annual_emissions_tonnes\": float(corporate_metrics['annual_projection_tonnes']),\n",
    "        \"per_developer_impact\": float(corporate_metrics['carbon_intensity_per_developer']),\n",
    "        \"daily_pipeline_runs\": corporate_metrics['daily_pipeline_runs']\n",
    "    },\n",
    "    \"workload_breakdown\": {\n",
    "        \"workloads\": results_df.to_dict('records'),\n",
    "        \"total_pipeline_emissions_g\": float(total_emissions),\n",
    "        \"most_intensive_workload\": highest_impact_workload['workload'],\n",
    "        \"least_intensive_workload\": most_efficient_workload['workload']\n",
    "    },\n",
    "    \"industry_benchmarking\": {\n",
    "        \"our_intensity_kg_per_dev\": float(our_intensity),\n",
    "        \"industry_benchmarks\": industry_benchmarks,\n",
    "        \"performance_vs_industry\": \"above\" if our_intensity > industry_benchmarks['software_industry_avg_kg_per_dev'] else \"below\"\n",
    "    },\n",
    "    \"sustainability_targets\": {\n",
    "        \"baseline_annual_kg\": float(baseline_emissions),\n",
    "        \"2025_target_kg\": float(baseline_emissions * (1 - targets['2025_reduction_target'])),\n",
    "        \"2030_target_kg\": float(baseline_emissions * (1 - targets['2030_reduction_target'])),\n",
    "        \"2040_net_zero_target_kg\": float(baseline_emissions * (1 - targets['2040_net_zero_target']))\n",
    "    },\n",
    "    \"optimization_recommendations\": [\n",
    "        {\n",
    "            \"category\": rec[\"category\"],\n",
    "            \"priority\": rec[\"priority\"],\n",
    "            \"recommendation\": rec[\"recommendation\"],\n",
    "            \"potential_savings\": rec[\"potential_savings\"],\n",
    "            \"implementation\": rec[\"implementation\"]\n",
    "        } for rec in recommendations\n",
    "    ],\n",
    "    \"economic_analysis\": {\n",
    "        \"annual_offset_cost_usd\": float(annual_offset_cost),\n",
    "        \"offset_cost_per_developer_usd\": float(annual_offset_cost / corporate_metrics['ml_team_size']),\n",
    "        \"offset_cost_per_pipeline_run_usd\": float(annual_offset_cost / (daily_runs * 365)),\n",
    "        \"carbon_price_per_tonne_usd\": carbon_offset_cost_per_tonne\n",
    "    },\n",
    "    \"contextual_impacts\": {\n",
    "        \"equivalent_car_km_annually\": float(corporate_metrics['equivalent_car_km_annually']),\n",
    "        \"trees_needed_for_offset\": float(corporate_metrics['equivalent_tree_years']),\n",
    "        \"smartphone_charges_equivalent\": float(corporate_metrics['annual_projection_kg'] * 1000 / 8.5)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save comprehensive sustainability report\n",
    "report_path = Path('./carbon_logs/sustainability_report.json')\n",
    "report_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(sustainability_report, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nüìÑ COMPREHENSIVE SUSTAINABILITY REPORT GENERATED\")\n",
    "print(f\"üíæ Report saved to: {report_path}\")\n",
    "print(f\"üìä Report includes: Executive summary, workload analysis, benchmarking, targets, and recommendations\")\n",
    "print(f\"üéØ Ready for ESG reporting and corporate sustainability initiatives\")\n",
    "\n",
    "# Display final summary for stakeholders\n",
    "print(f\"\\nüéâ SUSTAINABILITY ANALYSIS COMPLETE\")\n",
    "print(f\"=\" * 45)\n",
    "print(f\"‚úÖ Carbon footprint measured and analyzed\")\n",
    "print(f\"‚úÖ Optimization recommendations generated\")\n",
    "print(f\"‚úÖ Corporate ESG report prepared\")\n",
    "print(f\"‚úÖ Benchmarked against industry standards\")\n",
    "print(f\"‚úÖ Economic impact quantified\")\nprint(f\"\\nüí° Next steps: Implement high-priority recommendations and establish carbon budgets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Demo 6: Carbon-Aware Profiling Integration\n",
    "\n",
    "Demonstrate integration with performance profiling for comprehensive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate carbon-aware profiling (performance + sustainability)\n",
    "print(\"üîÑ CARBON-AWARE PROFILING INTEGRATION\")\n",
    "print(\"=\" * 48)\n",
    "\n",
    "# Initialize carbon-aware profiler\n",
    "carbon_profiler = CarbonAwareProfiler(\n",
    "    project_name=\"integrated-sustainability-demo\",\n",
    "    experiment_name=\"carbon-aware-ml-profiling\",\n",
    "    track_carbon=True\n",
    ")\n",
    "\n",
    "print(f\"üî¨ Carbon-aware profiler initialized\")\n",
    "print(f\"üìä Tracking both performance and sustainability metrics\")\n",
    "\n",
    "# Simulate a complete ML training workflow with combined tracking\n",
    "print(f\"\\nüöÄ Running integrated profiling on ML workflow...\")\n",
    "\n",
    "with carbon_profiler.profile_with_carbon(\"Integrated ML Workflow\") as session:\n",
    "    \n",
    "    print(f\"   üîÑ Starting data preprocessing...\")\n",
    "    # Simulate data preprocessing\n",
    "    for i in range(3):\n",
    "        data = np.random.randn(5000, 100)\n",
    "        processed = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "        features = np.dot(processed, np.random.randn(100, 50))\n",
    "        print(f\"      Batch {i+1}/3 preprocessed\")\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    print(f\"   üß† Starting model training...\")\n",
    "    # Simulate model training with both CPU and GPU operations\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(784, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(128, 10)\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(5):\n",
    "        epoch_loss = 0\n",
    "        for batch in range(10):\n",
    "            # Generate batch data\n",
    "            x = torch.randn(32, 784).to(device)\n",
    "            y = torch.randint(0, 10, (32,)).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / 10\n",
    "        print(f\"      Epoch {epoch+1}/5 - Loss: {avg_loss:.4f}\")\n",
    "        time.sleep(0.05)\n",
    "    \n",
    "    print(f\"   üìä Starting model evaluation...\")\n",
    "    # Simulate evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for eval_batch in range(5):\n",
    "            x_eval = torch.randn(64, 784).to(device)\n",
    "            y_eval = torch.randint(0, 10, (64,)).to(device)\n",
    "            predictions = model(x_eval)\n",
    "            accuracy = (predictions.argmax(1) == y_eval).float().mean()\n",
    "            \n",
    "            if eval_batch % 2 == 0:\n",
    "                print(f\"      Eval batch {eval_batch+1}/5 - Acc: {accuracy:.3f}\")\n",
    "            time.sleep(0.02)\n",
    "    \n",
    "    print(f\"   ‚úÖ Integrated ML workflow completed\")\n",
    "\n",
    "# Extract combined results\n",
    "combined_results = session.results\n",
    "\n",
    "print(f\"\\nüìä INTEGRATED ANALYSIS RESULTS\")\n",
    "print(f\"=\" * 40)\n",
    "\n",
    "if 'performance' in combined_results:\n",
    "    perf_metrics = combined_results['performance']\n",
    "    print(f\"üî¨ Performance Metrics:\")\n",
    "    if 'memory' in perf_metrics:\n",
    "        print(f\"   Peak RAM: {perf_metrics['memory'].get('peak_ram_mb', 0):.1f} MB\")\n",
    "    if 'timing' in perf_metrics:\n",
    "        print(f\"   Wall Time: {perf_metrics['timing'].get('wall_time_s', 0):.2f} seconds\")\n",
    "    if 'compute' in perf_metrics:\n",
    "        flops = perf_metrics['compute'].get('estimated_flops', 0)\n",
    "        if flops > 0:\n",
    "            print(f\"   Est. FLOPs: {flops:,}\")\n",
    "\n",
    "if 'carbon' in combined_results:\n",
    "    carbon_metrics = combined_results['carbon']\n",
    "    print(f\"\\nüå± Carbon Metrics:\")\n",
    "    emissions_g = carbon_metrics.get('emissions_kg_co2', 0) * 1000\n",
    "    energy_wh = carbon_metrics.get('energy_consumed_kwh', 0) * 1000\n",
    "    print(f\"   CO2 Emissions: {emissions_g:.3f}g\")\n",
    "    print(f\"   Energy Used: {energy_wh:.2f} Wh\")\n",
    "    \n",
    "    # Display intuitive comparisons if available\n",
    "    if 'comparisons' in combined_results:\n",
    "        comparisons = combined_results['comparisons']\n",
    "        print(f\"   Equivalent Impact:\")\n",
    "        for comparison_type, comparison_value in comparisons.items():\n",
    "            if comparison_type == 'phone_charges':\n",
    "                print(f\"     üì± {comparison_value}\")\n",
    "            elif comparison_type == 'car_driving_km':\n",
    "                print(f\"     üöó {comparison_value}\")\n",
    "\n",
    "# Calculate efficiency metrics\n",
    "if 'performance' in combined_results and 'carbon' in combined_results:\n",
    "    perf = combined_results['performance']\n",
    "    carbon = combined_results['carbon']\n",
    "    \n",
    "    wall_time = perf['timing'].get('wall_time_s', 1)\n",
    "    emissions = carbon.get('emissions_kg_co2', 0) * 1000\n",
    "    energy = carbon.get('energy_consumed_kwh', 0) * 1000\n",
    "    memory = perf['memory'].get('peak_ram_mb', 0)\n",
    "    \n",
    "    print(f\"\\n‚ö° EFFICIENCY METRICS:\")\n",
    "    print(f\"   Carbon Intensity: {emissions / wall_time:.4f}g CO2/second\")\n",
    "    print(f\"   Energy Efficiency: {energy / wall_time:.3f}Wh/second\")\n",
    "    print(f\"   Memory Efficiency: {memory / wall_time:.2f}MB/second\")\n",
    "    \n",
    "    if emissions > 0 and memory > 0:\n",
    "        carbon_per_mb = emissions / memory\n",
    "        print(f\"   Carbon per Memory: {carbon_per_mb:.6f}g CO2/MB\")\n",
    "\n",
    "print(f\"\\nüéØ INTEGRATED PROFILING BENEFITS:\")\n",
    "print(f\"   ‚úÖ Complete resource and environmental impact visibility\")\n",
    "print(f\"   ‚úÖ Unified optimization targeting both performance and sustainability\")\n",
    "print(f\"   ‚úÖ Single profiling session captures all relevant metrics\")\n",
    "print(f\"   ‚úÖ Ready for production monitoring and continuous optimization\")\n",
    "\n",
    "print(f\"\\nüåü This demonstrates the power of integrated sustainability + performance profiling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Summary & Strategic Impact\n",
    "\n",
    "This comprehensive demo showcased the carbon tracking capabilities of the ML Cookbook:\n",
    "\n",
    "### ‚úÖ Demonstrated Capabilities\n",
    "\n",
    "- **üåç Real Carbon Tracking** - CodeCarbon integration with regional carbon intensity data\n",
    "- **‚òÅÔ∏è Cloud Provider Optimization** - Automatic detection and regional recommendations\n",
    "- **üìä Intuitive Impact Comparisons** - Phone charges, car driving, tree absorption equivalents\n",
    "- **üí° Actionable Recommendations** - Specific optimization strategies with quantified savings\n",
    "- **üìà Corporate ESG Reporting** - Professional sustainability reports for stakeholder communication\n",
    "- **üîÑ Performance Integration** - Combined carbon and performance profiling for holistic optimization\n",
    "\n",
    "### üöÄ Production Applications\n",
    "\n",
    "- **Corporate Sustainability** - ESG reporting, carbon budgeting, and environmental compliance\n",
    "- **Cost Optimization** - Cloud region selection based on carbon intensity and compute costs\n",
    "- **Team Accountability** - Per-developer carbon tracking and team sustainability goals\n",
    "- **Production Monitoring** - Continuous carbon tracking in ML pipelines and model serving\n",
    "- **Regulatory Compliance** - Automated sustainability reporting for environmental regulations\n",
    "\n",
    "### üíº Strategic Business Impact\n",
    "\n",
    "This demonstrates forward-thinking capabilities aligned with critical business trends:\n",
    "\n",
    "- **ESG Leadership** - Proactive environmental responsibility in AI development\n",
    "- **Risk Management** - Preparation for carbon pricing and environmental regulations\n",
    "- **Brand Differentiation** - Sustainable AI as a competitive advantage\n",
    "- **Operational Excellence** - Data-driven sustainability decisions with measurable impact\n",
    "- **Stakeholder Value** - Clear communication of environmental stewardship to investors and customers\n",
    "\n",
    "### üåü Industry Innovation\n",
    "\n",
    "- **First-of-its-kind** integrated carbon tracking in ML development tools\n",
    "- **Actionable Intelligence** - Beyond measurement to concrete optimization recommendations\n",
    "- **Corporate-Ready** - Professional reporting that meets real business needs\n",
    "- **Developer-Friendly** - Seamless integration that doesn't disrupt existing workflows\n",
    "- **Future-Proof** - Addresses growing regulatory and market demands for sustainable AI\n",
    "\n",
    "### üîó Ecosystem Integration\n",
    "\n",
    "Carbon tracking enhances the complete ML engineering workflow:\n",
    "\n",
    "- **Performance Profiling** - Optimize for both speed and sustainability simultaneously\n",
    "- **Experiment Logging** - Track carbon impact alongside traditional ML metrics\n",
    "- **Statistical Validation** - Validate that optimizations provide significant carbon reduction\n",
    "- **Production Monitoring** - Continuous environmental impact monitoring in deployed systems\n",
    "\n",
    "---\n",
    "\n",
    "**üéØ Strategic Takeaway:** Carbon-aware ML development is not just environmentally responsible‚Äîit's a competitive advantage that reduces costs, manages regulatory risk, and demonstrates technical leadership in sustainable AI practices.\n",
    "\n",
    "**Built with the ML Cookbook - Professional ML Engineering Toolkit** üöÄüå±"
   ]
  }
 ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.8.0\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 4\n}